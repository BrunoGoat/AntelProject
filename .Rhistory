device_category = first(device_category),
source = first(source),
medium = first(medium)
) %>%
ungroup()
# Agrupar por sesión (ga_session_id) y resumir
session_df <- df_clean %>%
group_by(ga_session_id) %>%
summarise(
user_pseudo_id = first(user_pseudo_id),
user_engagement = any(event_name == "user_engagement"),
play = any(event_name == "play"),
session_start = any(event_name == "session_start"),
first_use = any(event_name == "first_open"),
screen_view_count = sum(event_name == "screen_view"),
firebase_screen_class = last(na.omit(firebase_screen_class)),
firebase_previous_class = last(na.omit(firebase_previous_class)),
firebase_event_origin = last(na.omit(firebase_event_origin)),
engagement_time_msec = sum(engagement_time_msec, na.rm = TRUE)
) %>%
ungroup()
# Unir al resumen principal
session_df <- session_df %>%
left_join(info_extra_sesion, by = "ga_session_id")
# Agregar info de tiempo y flags desde info_tiempo
session_df <- session_df %>%
left_join(info_tiempo, by = "ga_session_id")
session_df <- session_df %>%
rename(date = event_date, id = ga_session_id) %>%
select(
date, id, session_start, first_use, user_engagement,
engagement_time_msec, mean_event_timestamp, mean_event_previous_timestamp,
first_open_time, user_first_touch_timestamp, screen_view_count,
firebase_screen_class, firebase_previous_class, firebase_event_origin,
nro_events, device_category, platform, medium, source, geo_city,
geo_country, ads_storage, play
)
session_df <- session_df |>
mutate(nro_events_sin_play = ifelse(play == TRUE, nro_events - 1, nro_events))
save(session_df, file = "session_df.RData")
library(dplyr)
library(jsonlite)
library(tidyverse)
library(purrr)
# load saved data
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
load("data_cleaned.RData")
load("session_df.RData")
# load functions
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/functions")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/functions")
#Modifiquenlo y corranlo en la consola para no modificar el script
source("fixdatafunctions.R")
# Si no les funciona pueden abrir el archivo y cargar las dos funciones a mano
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/data")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/data")
#Modifiquenlo y corranlo en la consola para no modificar el script
clean_df <- clean_data_frame("primera_extracción_dataset.csv")
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(clean_df, file = "data_cleaned.RData")
sessions_df <- generate_sessions_df(clean_df)
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(sessions_df, file = "session_df.RData")
View(session_df)
View(session_df)
session_df <- session_df |> select(-nro_events)
save(session_df, file = "session_df.RData")
library(dplyr)
library(jsonlite)
library(tidyverse)
library(purrr)
library(tidyr)
load("data_cleaned.RData")
generate_sessions_df <- function(df) {
# 1) Extraer campos de interés desde event_params ------------------------
extraer_event_params <- function(x) {
tryCatch({
parsed <- fromJSON(x)
params <- parsed$event_params
resultado <- list(
engagement_time_msec     = 0,
firebase_screen_class    = NA_character_,
firebase_previous_class  = NA_character_,
firebase_event_origin    = NA_character_
)
for (i in seq_len(nrow(params))) {
key <- params$key[i]; val <- params$value[i, ]
if (key == "engagement_time_msec" && !is.null(val$int_value)) {
resultado$engagement_time_msec <- as.numeric(val$int_value)
} else if (key == "firebase_screen_class" && !is.null(val$string_value)) {
resultado$firebase_screen_class <- val$string_value
} else if (key == "firebase_previous_class" && !is.null(val$string_value)) {
resultado$firebase_previous_class <- val$string_value
} else if (key == "firebase_event_origin" && !is.null(val$string_value)) {
resultado$firebase_event_origin <- val$string_value
}
}
resultado
}, error = function(e) {
list(
engagement_time_msec     = 0,
firebase_screen_class    = NA_character_,
firebase_previous_class  = NA_character_,
firebase_event_origin    = NA_character_
)
})
}
# 2) Enriquecer df con event_params --------------------------------------
event_info <- map_dfr(df$event_params, extraer_event_params)
df2 <- bind_cols(df, event_info)
# 3) Unificar columnas con sufijos .x / .y ------------------------------
df2 <- df2 %>% mutate(
user_first_touch_timestamp = coalesce(user_first_touch_timestamp.x, user_first_touch_timestamp.y),
first_open_time            = coalesce(first_open_time.x,            first_open_time.y),
ads_storage                = coalesce(ads_storage.x,                ads_storage.y)
)
# 4) Info adicional por sesión ------------------------------------------ ------------------------------------------ por sesión ------------------------------------------
info_extra_sesion <- df2 %>%
group_by(ga_session_id) %>%
summarise(
event_date      = first(event_date),
platform        = first(platform),
geo_city        = first(geo_city),
geo_country     = first(geo_country),
device_category = first(device_category),
source          = first(source),
medium          = first(medium),
ads_storage     = first(ads_storage),
.groups = "drop"
)
# 5) Info temporal y conteos ---------------------------------------------
info_tiempo <- df2 %>%
group_by(ga_session_id) %>%
summarise(
mean_event_timestamp           = mean(event_timestamp,            na.rm = TRUE),
mean_event_previous_timestamp  = mean(event_previous_timestamp,   na.rm = TRUE),
first_open_time                = first(first_open_time),
user_first_touch_timestamp     = first(user_first_touch_timestamp),
nro_events                     = n(),
.groups = "drop"
)
# 6) Resumen principal por sesión ---------------------------------------
session_df <- df2 %>%
group_by(ga_session_id) %>%
summarise(
user_pseudo_id          = first(user_pseudo_id),
user_engagement         = any(event_name == "user_engagement"),
play                    = any(event_name == "play"),
session_start           = any(event_name == "session_start"),
first_use               = any(event_name == "first_open"),
screen_view_count       = sum(event_name == "screen_view"),
firebase_screen_class   = last(na.omit(firebase_screen_class)),
firebase_previous_class = last(na.omit(firebase_previous_class)),
firebase_event_origin   = last(na.omit(firebase_event_origin)),
engagement_time_msec    = sum(engagement_time_msec, na.rm = TRUE),
.groups = "drop"
) %>%
left_join(info_extra_sesion, by = "ga_session_id") %>%
left_join(info_tiempo,       by = "ga_session_id")
# 7) Renombrar y ordenar columnas ---------------------------------------
session_df %>%
rename(
date = event_date,
id   = ga_session_id
) %>%
select(
date, id, session_start, first_use, user_engagement,
engagement_time_msec, mean_event_timestamp, mean_event_previous_timestamp,
first_open_time, user_first_touch_timestamp, screen_view_count,
firebase_screen_class, firebase_previous_class, firebase_event_origin,
nro_events, device_category, platform, medium, source, geo_city,
geo_country, ads_storage, play
)
}
# Función para extraer campos de interés desde event_params
extraer_event_params <- function(x) {
tryCatch({
parsed <- fromJSON(x)
params <- parsed$event_params
resultado <- list(
engagement_time_msec = 0,
firebase_screen_class = NA_character_,
firebase_previous_class = NA_character_,
firebase_event_origin = NA_character_
)
for (i in seq_len(nrow(params))) {
key <- params$key[i]
val <- params$value[i, ]
if (key == "engagement_time_msec" && !is.null(val$int_value)) {
resultado$engagement_time_msec <- as.numeric(val$int_value)
} else if (key == "firebase_screen_class" && !is.null(val$string_value)) {
resultado$firebase_screen_class <- val$string_value
} else if (key == "firebase_previous_class" && !is.null(val$string_value)) {
resultado$firebase_previous_class <- val$string_value
} else if (key == "firebase_event_origin" && !is.null(val$string_value)) {
resultado$firebase_event_origin <- val$string_value
}
}
return(resultado)
}, error = function(e) {
return(list(
engagement_time_msec = 0,
firebase_screen_class = NA_character_,
firebase_previous_class = NA_character_,
firebase_event_origin = NA_character_
))
})
}
# Aplicar la extracción a cada fila
event_info <- map_dfr(df_clean$event_params, extraer_event_params)
# Combinar con df_clean
df_clean <- bind_cols(df_clean, event_info)
# Información adicional por sesión
info_extra_sesion <- df_clean %>%
group_by(ga_session_id) %>%
summarise(
event_date = first(event_date),
platform = first(platform),
geo_city = first(geo_city),
geo_country = first(geo_country),
device_category = first(device_category),
source = first(source),
medium = first(medium)
) %>%
ungroup()
# Agrupar por sesión (ga_session_id) y resumir
session_df <- df_clean %>%
group_by(ga_session_id) %>%
summarise(
user_pseudo_id = first(user_pseudo_id),
user_engagement = any(event_name == "user_engagement"),
play = any(event_name == "play"),
session_start = any(event_name == "session_start"),
first_use = any(event_name == "first_open"),
screen_view_count = sum(event_name == "screen_view"),
firebase_screen_class = last(na.omit(firebase_screen_class)),
firebase_previous_class = last(na.omit(firebase_previous_class)),
firebase_event_origin = last(na.omit(firebase_event_origin)),
engagement_time_msec = sum(engagement_time_msec, na.rm = TRUE)
) %>%
ungroup()
# Unir al resumen principal
session_df <- session_df %>%
left_join(info_extra_sesion, by = "ga_session_id")
# Agregar info de tiempo y flags desde info_tiempo
session_df <- session_df %>%
left_join(info_tiempo, by = "ga_session_id")
session_df <- session_df %>%
rename(date = event_date, id = ga_session_id) %>%
select(
date, id, session_start, first_use, user_engagement,
engagement_time_msec, mean_event_timestamp, mean_event_previous_timestamp,
first_open_time, user_first_touch_timestamp, screen_view_count,
firebase_screen_class, firebase_previous_class, firebase_event_origin,
nro_events, device_category, platform, medium, source, geo_city,
geo_country, ads_storage, play
)
session_df <- session_df |>
mutate(nro_events_sin_play = ifelse(play == TRUE, nro_events - 1, nro_events))
session_df <- session_df |> select(-nro_events)
save(session_df, file = "session_df.RData")
library(dplyr)
library(jsonlite)
library(tidyverse)
library(purrr)
# load saved data
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
load("data_cleaned.RData")
load("session_df.RData")
# load functions
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/functions")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/functions")
#Modifiquenlo y corranlo en la consola para no modificar el script
source("fixdatafunctions.R")
# Si no les funciona pueden abrir el archivo y cargar las dos funciones a mano
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/data")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/data")
#Modifiquenlo y corranlo en la consola para no modificar el script
clean_df <- clean_data_frame("primera_extracción_dataset.csv")
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(clean_df, file = "data_cleaned.RData")
sessions_df <- generate_sessions_df(clean_df)
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(sessions_df, file = "session_df.RData")
# =====================
# 1. Cargar librerías
# =====================
library(readr)
library(dplyr)
library(caret)
library(randomForest)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = TRUE)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = TRUE)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = FALSE)
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject")
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = TRUE)
# =====================
# 3. Verificar variable objetivo
# =====================
df$play <- as.factor(df$play)
# =====================
# 4. Eliminar columnas no predictivas
# =====================
df_model <- df %>%
select(-id, -date)
# =====================
# 5. Imputación de valores faltantes
# =====================
df_model <- df_model %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor), ~ {
moda <- names(sort(table(.), decreasing = TRUE))[1]
factor(ifelse(is.na(.), moda, as.character(.)), levels = levels(.))
}))
# =====================
# 6. División en conjunto de entrenamiento y test
# =====================
set.seed(123)
train_idx <- createDataPartition(df_model$play, p = 0.7, list = FALSE)
train_data <- df_model[train_idx, ]
test_data  <- df_model[-train_idx, ]
# =====================
# 7. Entrenamiento del modelo Random Forest
# =====================
modelo_rf <- randomForest(play ~ ., data = train_data, ntree = 500, importance = TRUE)
# =====================
# 8. Predicción sobre el conjunto de test
# =====================
pred_rf <- predict(modelo_rf, newdata = test_data)
# =====================
# 9. Evaluación del modelo
# =====================
conf_mat <- confusionMatrix(pred_rf, test_data$play)
print(conf_mat)
# =====================
# 10. Comparación: predicho vs real
# =====================
comparacion <- data.frame(
predicho = pred_rf,
real = test_data$play
)
# Ver primeros 20
head(comparacion, 20)
# Agregar columna de acierto
comparacion <- comparacion %>%
mutate(acierto = predicho == real)
# Ver conteo de aciertos y errores
table(comparacion$acierto)
# Ver porcentaje de aciertos (accuracy manual)
mean(comparacion$acierto)
# =====================
# 11. Importancia de variables
# =====================
varImpPlot(modelo_rf)
colnames(train_data)
View(df)
sessions_df <- generate_sessions_df(clean_df)
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(sessions_df, file = "session_df.RData")
load("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/session_df.RData")
load("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/session_df.RData")
View(session_df)
View(session_df)
View(sessions_df)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = TRUE)
View(df)
library(dplyr)
library(jsonlite)
library(tidyverse)
library(purrr)
# load saved data
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
load("data_cleaned.RData")
load("session_df.RData")
# load functions
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/functions")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/functions")
#Modifiquenlo y corranlo en la consola para no modificar el script
source("fixdatafunctions.R")
# Si no les funciona pueden abrir el archivo y cargar las dos funciones a mano
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/data")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/data")
#Modifiquenlo y corranlo en la consola para no modificar el script
clean_df <- clean_data_frame("primera_extracción_dataset.csv")
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(clean_df, file = "data_cleaned.RData")
sessions_df <- generate_sessions_df(clean_df)
setwd("C:/Users/IdeaV15/Desktop/Estadistica/Antel_Proyect/AntelProject/Rdata")
#setwd("C:/Users/walte/OneDrive/Desktop/Antel/AntelRep/AntelProject/Rdata")
#Modifiquenlo y corranlo en la consola para no modificar el script
save(sessions_df, file = "session_df.RData")
write.csv(session_df, "session_df.csv", row.names = FALSE)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/session_df.csv", stringsAsFactors = TRUE)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/sessions_df.csv", stringsAsFactors = TRUE)
View(df)
# =====================
# 2. Cargar el archivo CSV
# =====================
df <- read.csv("Rdata/session_df.csv", stringsAsFactors = TRUE)
View(df)
# =====================
# 3. Verificar variable objetivo
# =====================
df$play <- as.factor(df$play)
# =====================
# 4. Eliminar columnas no predictivas
# =====================
df_model <- df %>%
select(-id, -date)
# =====================
# 5. Imputación de valores faltantes
# =====================
df_model <- df_model %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor), ~ {
moda <- names(sort(table(.), decreasing = TRUE))[1]
factor(ifelse(is.na(.), moda, as.character(.)), levels = levels(.))
}))
# =====================
# 6. División en conjunto de entrenamiento y test
# =====================
set.seed(123)
train_idx <- createDataPartition(df_model$play, p = 0.7, list = FALSE)
train_data <- df_model[train_idx, ]
test_data  <- df_model[-train_idx, ]
# =====================
# 7. Entrenamiento del modelo Random Forest
# =====================
modelo_rf <- randomForest(play ~ ., data = train_data, ntree = 500, importance = TRUE)
# =====================
# 8. Predicción sobre el conjunto de test
# =====================
pred_rf <- predict(modelo_rf, newdata = test_data)
# =====================
# 9. Evaluación del modelo
# =====================
conf_mat <- confusionMatrix(pred_rf, test_data$play)
print(conf_mat)
# =====================
# 10. Comparación: predicho vs real
# =====================
comparacion <- data.frame(
predicho = pred_rf,
real = test_data$play
)
# Ver primeros 20
head(comparacion, 20)
# Agregar columna de acierto
comparacion <- comparacion %>%
mutate(acierto = predicho == real)
# Ver conteo de aciertos y errores
table(comparacion$acierto)
# Ver porcentaje de aciertos (accuracy manual)
mean(comparacion$acierto)
# =====================
# 11. Importancia de variables
# =====================
varImpPlot(modelo_rf)
colnames(train_data)
library(caret)
confusionMatrix(pred_rf, test_data$play, positive = "TRUE")
colnames(train_data)
# =====================
# 11. Importancia de variables
# =====================
varImpPlot(modelo_rf)
# Ver conteo de aciertos y errores
table(comparacion$acierto)
importance(modelo_rf)
# Como data frame
importance_df <- as.data.frame(importance(modelo_rf))
importance_df <- importance_df[order(-importance_df$MeanDecreaseAccuracy), ]
head(importance_df, 10)  # Las 10 más importantes
